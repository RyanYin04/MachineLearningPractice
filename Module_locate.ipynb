{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "\n",
    "import re\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('../Data/CloudSOP_Data/cloudsop_2020_data_tidied.csv')\n",
    "raw_data.drop('Unnamed: 0', axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(112280, 14)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "raw_data.columns\n",
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(77581, 14)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# 移除module为空的行：\n",
    "df = raw_data.dropna(axis = 0, subset = ['MODULE'])\n",
    "df.shape"
   ]
  },
  {
   "source": [
    "test_desc = raw_data.DISCRIPT[0]\n",
    "test_desc"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'【拓扑适配】【新需求---US20200804307566 OpenORB由于衰退期软件需要切换】【自动发现】导入IP地址后点击保存IP地址，保存后再次打开自动发现，保存的IP只不存在，请定位'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  },
  {
   "source": [
    "### 分词："
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stop_words(file):\n",
    "    stopwords = []\n",
    "    with open(file, encoding='utf-8') as f:\n",
    "        while True:\n",
    "            word = f.readline()\n",
    "            word = re.sub(r'\\s', '', word)\n",
    "            # print(word)\n",
    "            if word:\n",
    "                stopwords.append(word)\n",
    "            elif not word:\n",
    "                break\n",
    "    return stopwords\n",
    "\n",
    "def jieba_cut_without_stopwords(sentence, stop_words):\n",
    "    res = jieba.cut(sentence)\n",
    "    cutted = []\n",
    "    for s in res:\n",
    "        if s not in stop_words:\n",
    "            cutted.append(s)\n",
    "    return cutted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Y00591~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.707 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# 分词并移除stop_words\n",
    "stop_words = load_stop_words('hit_stopwords.txt')\n",
    "df['CUTTED'] = df.DISCRIPT.apply(lambda x: jieba_cut_without_stopwords(x, stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MODULE'] = df.MODULE.apply(int)\n",
    "df['MODULE'] = df.MODULE.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 NO                                           DISCRIPT  \\\n",
       "0  DTS2020092908555  【拓扑适配】【新需求---US20200804307566 OpenORB由于衰退期软件需要...   \n",
       "1  DTS2020092908555  【拓扑适配】【新需求---US20200804307566 OpenORB由于衰退期软件需要...   \n",
       "2  DTS2020093003837  【R21RR4】【Super】【MOUI】资源跳转MOUI界面后应默认进入总览，当前进入的是...   \n",
       "3  DTS2020093003837  【R21RR4】【Super】【MOUI】资源跳转MOUI界面后应默认进入总览，当前进入的是...   \n",
       "4  DTS2020093003837  【R21RR4】【Super】【MOUI】资源跳转MOUI界面后应默认进入总览，当前进入的是...   \n",
       "\n",
       "                CREATOR SDEPT3SUBMIT          SORIGINTYPE SODCATIVITYNO  \\\n",
       "0  jiahonghong WX335476    管控析集成与验证部  2020-09-29 00:00:00       有条件必然重现   \n",
       "1  jiahonghong WX335476    管控析集成与验证部  2020-09-29 00:00:00       有条件必然重现   \n",
       "2        wuxing WX80136    管控析集成与验证部  2020-09-30 00:00:00       有条件必然重现   \n",
       "3        wuxing WX80136    管控析集成与验证部  2020-09-30 00:00:00       有条件必然重现   \n",
       "4        wuxing WX80136    管控析集成与验证部  2020-09-30 00:00:00       有条件必然重现   \n",
       "\n",
       "                         BVERSION  \\\n",
       "0  CloudSOP V100R021C10SPC410B401   \n",
       "1  CloudSOP V100R021C10SPC410B401   \n",
       "2  CloudSOP V100R021C10SPC410B002   \n",
       "3  CloudSOP V100R021C10SPC410B002   \n",
       "4  CloudSOP V100R021C10SPC410B002   \n",
       "\n",
       "                                   DATAILDESCRIPTION  \\\n",
       "0  <p>【环境】<br>  <br>  https://8.7.242.118:31943/t...   \n",
       "1  <p>【环境】<br>  <br>  https://8.7.242.118:31943/t...   \n",
       "2  <p>【测试环境】https://8.7.242.179:31943/<br> 【步骤与现象...   \n",
       "3  <p>【测试环境】https://8.7.242.179:31943/<br> 【步骤与现象...   \n",
       "4  <p>【测试环境】https://8.7.242.179:31943/<br> 【步骤与现象...   \n",
       "\n",
       "                                           FILE_PATH          CREATE_TIME  \\\n",
       "0  gnldev/gnldev/impl/server/source/src/gnldev/so...  2020-10-23 14:31:24   \n",
       "1  eam/eam/impl/server/source/src/eam_common/EAMD...  2020-10-23 14:31:24   \n",
       "2    website/src/main/webapp/source/src/moui/main.js  2020-10-20 09:50:37   \n",
       "3    website/src/main/webapp/source/src/moui/main.js  2020-10-30 17:40:42   \n",
       "4    website/src/main/webapp/source/src/moui/main.js  2020-11-03 16:15:57   \n",
       "\n",
       "  FEATURE      MODULE MICROSERVICE           RVERSION  \\\n",
       "0     NaN  1110352450  TopoWebsite  CloudSOP V100R021   \n",
       "1     NaN  1110352450  TopoWebsite  CloudSOP V100R021   \n",
       "2     NaN  1110352462          NaN  CloudSOP V100R021   \n",
       "3     NaN  1110352462          NaN  CloudSOP V100R021   \n",
       "4     NaN  1110352462          NaN  CloudSOP V100R021   \n",
       "\n",
       "                                              CUTTED  \n",
       "0  [拓扑, 适配, 新, 需求, ---, US20200804307566,  , Open...  \n",
       "1  [拓扑, 适配, 新, 需求, ---, US20200804307566,  , Open...  \n",
       "2  [R21RR4, Super, MOUI, 资源, 跳转, MOUI, 界面, 后应, 默认...  \n",
       "3  [R21RR4, Super, MOUI, 资源, 跳转, MOUI, 界面, 后应, 默认...  \n",
       "4  [R21RR4, Super, MOUI, 资源, 跳转, MOUI, 界面, 后应, 默认...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NO</th>\n      <th>DISCRIPT</th>\n      <th>CREATOR</th>\n      <th>SDEPT3SUBMIT</th>\n      <th>SORIGINTYPE</th>\n      <th>SODCATIVITYNO</th>\n      <th>BVERSION</th>\n      <th>DATAILDESCRIPTION</th>\n      <th>FILE_PATH</th>\n      <th>CREATE_TIME</th>\n      <th>FEATURE</th>\n      <th>MODULE</th>\n      <th>MICROSERVICE</th>\n      <th>RVERSION</th>\n      <th>CUTTED</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DTS2020092908555</td>\n      <td>【拓扑适配】【新需求---US20200804307566 OpenORB由于衰退期软件需要...</td>\n      <td>jiahonghong WX335476</td>\n      <td>管控析集成与验证部</td>\n      <td>2020-09-29 00:00:00</td>\n      <td>有条件必然重现</td>\n      <td>CloudSOP V100R021C10SPC410B401</td>\n      <td>&lt;p&gt;【环境】&lt;br&gt;  &lt;br&gt;  https://8.7.242.118:31943/t...</td>\n      <td>gnldev/gnldev/impl/server/source/src/gnldev/so...</td>\n      <td>2020-10-23 14:31:24</td>\n      <td>NaN</td>\n      <td>1110352450</td>\n      <td>TopoWebsite</td>\n      <td>CloudSOP V100R021</td>\n      <td>[拓扑, 适配, 新, 需求, ---, US20200804307566,  , Open...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DTS2020092908555</td>\n      <td>【拓扑适配】【新需求---US20200804307566 OpenORB由于衰退期软件需要...</td>\n      <td>jiahonghong WX335476</td>\n      <td>管控析集成与验证部</td>\n      <td>2020-09-29 00:00:00</td>\n      <td>有条件必然重现</td>\n      <td>CloudSOP V100R021C10SPC410B401</td>\n      <td>&lt;p&gt;【环境】&lt;br&gt;  &lt;br&gt;  https://8.7.242.118:31943/t...</td>\n      <td>eam/eam/impl/server/source/src/eam_common/EAMD...</td>\n      <td>2020-10-23 14:31:24</td>\n      <td>NaN</td>\n      <td>1110352450</td>\n      <td>TopoWebsite</td>\n      <td>CloudSOP V100R021</td>\n      <td>[拓扑, 适配, 新, 需求, ---, US20200804307566,  , Open...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DTS2020093003837</td>\n      <td>【R21RR4】【Super】【MOUI】资源跳转MOUI界面后应默认进入总览，当前进入的是...</td>\n      <td>wuxing WX80136</td>\n      <td>管控析集成与验证部</td>\n      <td>2020-09-30 00:00:00</td>\n      <td>有条件必然重现</td>\n      <td>CloudSOP V100R021C10SPC410B002</td>\n      <td>&lt;p&gt;【测试环境】https://8.7.242.179:31943/&lt;br&gt; 【步骤与现象...</td>\n      <td>website/src/main/webapp/source/src/moui/main.js</td>\n      <td>2020-10-20 09:50:37</td>\n      <td>NaN</td>\n      <td>1110352462</td>\n      <td>NaN</td>\n      <td>CloudSOP V100R021</td>\n      <td>[R21RR4, Super, MOUI, 资源, 跳转, MOUI, 界面, 后应, 默认...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DTS2020093003837</td>\n      <td>【R21RR4】【Super】【MOUI】资源跳转MOUI界面后应默认进入总览，当前进入的是...</td>\n      <td>wuxing WX80136</td>\n      <td>管控析集成与验证部</td>\n      <td>2020-09-30 00:00:00</td>\n      <td>有条件必然重现</td>\n      <td>CloudSOP V100R021C10SPC410B002</td>\n      <td>&lt;p&gt;【测试环境】https://8.7.242.179:31943/&lt;br&gt; 【步骤与现象...</td>\n      <td>website/src/main/webapp/source/src/moui/main.js</td>\n      <td>2020-10-30 17:40:42</td>\n      <td>NaN</td>\n      <td>1110352462</td>\n      <td>NaN</td>\n      <td>CloudSOP V100R021</td>\n      <td>[R21RR4, Super, MOUI, 资源, 跳转, MOUI, 界面, 后应, 默认...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DTS2020093003837</td>\n      <td>【R21RR4】【Super】【MOUI】资源跳转MOUI界面后应默认进入总览，当前进入的是...</td>\n      <td>wuxing WX80136</td>\n      <td>管控析集成与验证部</td>\n      <td>2020-09-30 00:00:00</td>\n      <td>有条件必然重现</td>\n      <td>CloudSOP V100R021C10SPC410B002</td>\n      <td>&lt;p&gt;【测试环境】https://8.7.242.179:31943/&lt;br&gt; 【步骤与现象...</td>\n      <td>website/src/main/webapp/source/src/moui/main.js</td>\n      <td>2020-11-03 16:15:57</td>\n      <td>NaN</td>\n      <td>1110352462</td>\n      <td>NaN</td>\n      <td>CloudSOP V100R021</td>\n      <td>[R21RR4, Super, MOUI, 资源, 跳转, MOUI, 界面, 后应, 默认...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "## 向量化"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 使用tf-idf\n",
    "为了实现对中文更好的分词，结合jieba分词\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TfidfVectorizer(stop_words=['———', '》），', '）÷（１－', '”，', '）、', '＝（', ':', '→',\n",
       "                            '℃', '&', '*', '一一', '~~~~', '’', '.', '『', '.一',\n",
       "                            './', '--', '』', '＝″', '【', '［＊］', '｝＞', '［⑤］］',\n",
       "                            '［①Ｄ］', 'ｃ］', 'ｎｇ昉', '＊', '//', ...],\n",
       "                tokenizer=<bound method Tokenizer.cut of <Tokenizer dictionary=None>>)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer = jieba.cut, stop_words = stop_words)\n",
    "vectorizer.fit(df.DISCRIPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = vectorizer.transform(df.DISCRIPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成训练集和测试集：\n",
    "x_train, x_test, y_train, y_test = train_test_split(sparse_matrix, df[['MODULE', 'RVERSION']],test_size = 0.2, random_state = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([['1107652938', 'CloudSOP V100R007'],\n",
       "       ['1111078192', 'CloudSOP V100R021'],\n",
       "       ['1112191484', 'CloudSOP V100R021'],\n",
       "       ...,\n",
       "       ['1112191492', 'CloudSOP V100R021'],\n",
       "       ['1107652938', 'CloudSOP V100R007'],\n",
       "       ['1108737242', 'CloudSOP V100R007']], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "y_train.to_numpy()"
   ]
  },
  {
   "source": [
    "### Naiive Bayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB,  MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           MODULE           RVERSION\n",
       "57436  1107652938  CloudSOP V100R007\n",
       "45430  1111078192  CloudSOP V100R021\n",
       "14125  1112191484  CloudSOP V100R021\n",
       "35483  1110352374  CloudSOP V100R021\n",
       "41245  1110352274  CloudSOP V100R021\n",
       "...           ...                ...\n",
       "64916  1107652696  CloudSOP V100R021\n",
       "84947  1110352460  CloudSOP V100R021\n",
       "13826  1112191492  CloudSOP V100R021\n",
       "57601  1107652938  CloudSOP V100R007\n",
       "70620  1108737242  CloudSOP V100R007\n",
       "\n",
       "[62064 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MODULE</th>\n      <th>RVERSION</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>57436</th>\n      <td>1107652938</td>\n      <td>CloudSOP V100R007</td>\n    </tr>\n    <tr>\n      <th>45430</th>\n      <td>1111078192</td>\n      <td>CloudSOP V100R021</td>\n    </tr>\n    <tr>\n      <th>14125</th>\n      <td>1112191484</td>\n      <td>CloudSOP V100R021</td>\n    </tr>\n    <tr>\n      <th>35483</th>\n      <td>1110352374</td>\n      <td>CloudSOP V100R021</td>\n    </tr>\n    <tr>\n      <th>41245</th>\n      <td>1110352274</td>\n      <td>CloudSOP V100R021</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>64916</th>\n      <td>1107652696</td>\n      <td>CloudSOP V100R021</td>\n    </tr>\n    <tr>\n      <th>84947</th>\n      <td>1110352460</td>\n      <td>CloudSOP V100R021</td>\n    </tr>\n    <tr>\n      <th>13826</th>\n      <td>1112191492</td>\n      <td>CloudSOP V100R021</td>\n    </tr>\n    <tr>\n      <th>57601</th>\n      <td>1107652938</td>\n      <td>CloudSOP V100R007</td>\n    </tr>\n    <tr>\n      <th>70620</th>\n      <td>1108737242</td>\n      <td>CloudSOP V100R007</td>\n    </tr>\n  </tbody>\n</table>\n<p>62064 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "cnb = ComplementNB()\n",
    "cnb.fit(x_train, y_train.MODULE.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.00249464, 0.00249473, 0.00249386, ..., 0.00249473, 0.00249363,\n",
       "        0.00249438],\n",
       "       [0.0026038 , 0.00260388, 0.00260356, ..., 0.00260344, 0.00260859,\n",
       "        0.00260393],\n",
       "       [0.00260772, 0.00260733, 0.00260744, ..., 0.00260905, 0.00260817,\n",
       "        0.00260798],\n",
       "       ...,\n",
       "       [0.00259172, 0.00259145, 0.00259214, ..., 0.00259132, 0.00258623,\n",
       "        0.00259187],\n",
       "       [0.00260717, 0.00260674, 0.00260693, ..., 0.00260701, 0.00262244,\n",
       "        0.00260733],\n",
       "       [0.00260942, 0.00260911, 0.0026092 , ..., 0.00261054, 0.00260478,\n",
       "        0.00260953]])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "def top_k(proba_arr, y_arr, k = 3):\n",
    "    res = np.zeros(shape = (arr.shape[0], k))\n",
    "    for i, a in enumerate(arr):\n",
    "        n_largest_proba = heapq.nlargest(k, a)\n",
    "        idx = np.where(np.isin(a, n_largest_proba) == True)\n",
    "        n_largest_item = y_arr[idx]\n",
    "        res[i] = n_largest_item\n",
    "    return res\n",
    "\n",
    "arr = cnb.predict_proba(x_test)\n",
    "top_k(arr, cnb.classes_)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([False, False, False])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "tt = [np.array(10)]\n",
    "tt.append(np.array(11))\n",
    "tt\n",
    "arr_test = np.array([1,2,3])\n",
    "arr_test == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesCLF:\n",
    "    def __init__(self, model = 'Complement',):\n",
    "        try:\n",
    "            if model == 'Complement':\n",
    "                self.__clf__ = ComplementNB()\n",
    "            elif model == 'Multinomial':\n",
    "                self.__clf__ = MultinomialNB()\n",
    "        \n",
    "            print(self.__clf__)\n",
    "        \n",
    "        except:\n",
    "            print('Model not found')\n",
    "    \n",
    "    def fit(self, x_test, y_test):\n",
    "        '''\n",
    "        x_test: n*p1\n",
    "        y_test: n*1\n",
    "        '''\n",
    "        self.__clf__.fit(x_test, y_test)\n",
    "        self.modules = self.__clf__.classes_\n",
    "        \n",
    "    def predict(self, x):\n",
    "        '''\n",
    "        x: n*p\n",
    "        '''\n",
    "        return self.__clf__.predict(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return self.__clf__.predict_proba(x)\n",
    "\n",
    "    def predict_top_k(self, x, k = 3):\n",
    "        res = np.zeros(shape = (x.shape[0], k), dtype = np.object)\n",
    "        scores = self.__clf__.predict_proba(x)\n",
    "\n",
    "        for i, score in enumerate(scores):\n",
    "            # print(a)\n",
    "            n_largest_proba = heapq.nlargest(k, score)\n",
    "            idx = np.where(np.isin(score, n_largest_proba) == True)\n",
    "\n",
    "            n_largest_item = self.modules[idx]\n",
    "            tmp = n_largest_item\n",
    "\n",
    "            res[i] = tmp\n",
    "        return res     \n",
    "\n",
    "    def accuracy(self, y_true, y_predict, top_k = 3):\n",
    "        count = 0\n",
    "        for i in range(y_true.shape[0]):\n",
    "            # if i % 1000 == 0:\n",
    "            #     print(i) \n",
    "            #     # print(y_predict[i], y_true[i])\n",
    "            if y_true[i] in y_predict[i]:\n",
    "                count += 1\n",
    "\n",
    "        accuracy = count / y_true.shape[0]\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ComplementNB()\nMultinomialNB()\nModel not found\n"
     ]
    }
   ],
   "source": [
    "# 创建分类器：\n",
    "CNB = BayesCLF(model = 'Complement')\n",
    "MNB = BayesCLF(model = 'Multinomial')\n",
    "FNB = BayesCLF(model = 'fake')\n",
    "CNB.fit(x_train, y_train.MODULE.to_numpy())\n",
    "MNB.fit(x_train, y_train.MODULE.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([['1110352380', '1112191494', '1112191506'],\n",
       "       ['1107652706', '1108737097', '1110352436'],\n",
       "       ['1110352368', '1110352382', '1110352392'],\n",
       "       ...,\n",
       "       ['1110352408', '1110352508', '1111851251'],\n",
       "       ['1112191484', '1112191492', '1112191500'],\n",
       "       ['1110352422', '1110352436', '1111851247']], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# 预测：\n",
    "CNB.predict_top_k(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold 方法\n",
    "from sklearn.model_selection import KFold\n",
    "def kfold(clf, x, y, k):\n",
    "    '''\n",
    "    clf: classifier.\n",
    "    k: number of folds\n",
    "    '''\n",
    "    accs = []\n",
    "\n",
    "    kf = KFold(n_splits = k)\n",
    "    i = 1\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_predict = clf.predict_top_k(x_test, k = 3)\n",
    "\n",
    "        acc = clf.accuracy(y_test, y_predict)\n",
    "        accs.append(acc)\n",
    "        print('FOLD: {} ======= Accuracy: {}'.format(i, acc))\n",
    "        i += 1\n",
    "\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ComplementNB()\n",
      "FOLD: 1 ======= Accuracy: 0.6380976930016755\n",
      "FOLD: 2 ======= Accuracy: 0.6158803815416345\n",
      "FOLD: 3 ======= Accuracy: 0.580046403712297\n",
      "FOLD: 4 ======= Accuracy: 0.41505542665635475\n",
      "FOLD: 5 ======= Accuracy: 0.4529517916988915\n",
      "FOLD: 6 ======= Accuracy: 0.44753802526424336\n",
      "FOLD: 7 ======= Accuracy: 0.3993297241557102\n",
      "FOLD: 8 ======= Accuracy: 0.4466357308584687\n",
      "FOLD: 9 ======= Accuracy: 0.674400618716164\n",
      "FOLD: 10 ======= Accuracy: 0.6607373034287187\n",
      "MultinomialNB()\n",
      "FOLD: 1 ======= Accuracy: 0.5587060188168579\n",
      "FOLD: 2 ======= Accuracy: 0.5288734209847898\n",
      "FOLD: 3 ======= Accuracy: 0.5988656870327403\n",
      "FOLD: 4 ======= Accuracy: 0.33874709976798145\n",
      "FOLD: 5 ======= Accuracy: 0.3689095127610209\n",
      "FOLD: 6 ======= Accuracy: 0.35666408868265015\n",
      "FOLD: 7 ======= Accuracy: 0.31567414282031453\n",
      "FOLD: 8 ======= Accuracy: 0.35692188708430006\n",
      "FOLD: 9 ======= Accuracy: 0.6053106470739882\n",
      "FOLD: 10 ======= Accuracy: 0.5784996133023975\n"
     ]
    }
   ],
   "source": [
    "# 计算CNB的10-Fold的准确率\n",
    "accs1 = kfold(BayesCLF(), sparse_matrix, df.MODULE.to_numpy(), 10)\n",
    "accs2 = kfold(BayesCLF(model='Multinomial'), sparse_matrix, df.MODULE.to_numpy(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.5330673099034159, 0.4607172118327041)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# 计算平均准确率\n",
    "sum(accs1)/len(accs1), sum(accs2)/len(accs2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([['1110352384', '1110352420', '1110352546']], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# 案列试算: **DTS2020121400802**\n",
    "# 模块PBI编号：**1110352547** \n",
    "CNB.predict_top_k(vectorizer.transform(['【AIFM】【DCN】DCN需要支撑新的License部署场景，无平台License服务时，产品自行控制是否能够进入Incident界面']))"
   ]
  },
  {
   "source": [
    "实现按照R版本隔离，实现方案：\n",
    "\n",
    "1. 输入数据时，同时保存各样本的module信息，将预测出来的对应模块的概率设置为0，再推送结果\n",
    "2. 将 R版本作为输入，和proba一起作为输入放入LR进行一次分类\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CloudSOP V100R021    58507\n",
       "CloudSOP V100R007    18984\n",
       "CloudSOP V100R006       35\n",
       "CloudSOP V100R002        8\n",
       "CloudSOP V100R003        1\n",
       "Name: RVERSION, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "df.RVERSION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 对R版本进行onehot 编码\n",
    "X = y_train['RVERSION'].fillna('No record')\n",
    "x = X.to_numpy().reshape(-1, 1)\n",
    "enc = OneHotEncoder()\n",
    "x = enc.fit_transform(x)\n",
    "\n",
    "# 采用随机森林的方法，针对R版本进行预测\n",
    "dtc = DecisionTreeClassifier(random_state=0)\n",
    "dtc.fit(x, y_train['MODULE'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ComplementNB()\n"
     ]
    }
   ],
   "source": [
    "CNB2 = BayesCLF()\n",
    "CNB2.fit(x_train, y_train['MODULE'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "metadata": {},
     "execution_count": 160
    }
   ],
   "source": [
    "sum(prob1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = 30\n",
    "\n",
    "CNB2.predict_top_k(x_test)\n",
    "prob1 = CNB2.predict_proba(x_test)[test_index].reshape(-1, 1)\n",
    "rr = enc.transform(np.array(y_test['RVERSION'].to_numpy()[test_index]).reshape(-1, 1))\n",
    "prob2 = dtc.predict_proba(rr).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([0.19047133]), array([0.10091433]), array([0.0333843])]"
      ]
     },
     "metadata": {},
     "execution_count": 176
    }
   ],
   "source": [
    "heapq.nlargest(3, (prob1 * prob2) / sum(prob1 * prob2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.00249464, 0.00249473, 0.00249386, ..., 0.00249473, 0.00249363,\n",
       "        0.00249438],\n",
       "       [0.0026038 , 0.00260388, 0.00260356, ..., 0.00260344, 0.00260859,\n",
       "        0.00260393],\n",
       "       [0.00260772, 0.00260733, 0.00260744, ..., 0.00260905, 0.00260817,\n",
       "        0.00260798],\n",
       "       ...,\n",
       "       [0.00259172, 0.00259145, 0.00259214, ..., 0.00259132, 0.00258623,\n",
       "        0.00259187],\n",
       "       [0.00260717, 0.00260674, 0.00260693, ..., 0.00260701, 0.00262244,\n",
       "        0.00260733],\n",
       "       [0.00260942, 0.00260911, 0.0026092 , ..., 0.00261054, 0.00260478,\n",
       "        0.00260953]])"
      ]
     },
     "metadata": {},
     "execution_count": 178
    }
   ],
   "source": [
    "CNB2.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-184-2248856afc1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'RVERSION'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;31m# validation of X happens in _check_X called by _transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[0mX_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_int\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X, handle_unknown)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mX_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mX_int\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'iloc'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ndim'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m# if not a dataframe, do normal check_array validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mX_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             if (not hasattr(X, 'dtype')\n\u001b[0;32m     45\u001b[0m                     and np.issubdtype(X_temp.dtype, np.str_)):\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input contains NaN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "----\n",
    "## Word2Vec\n",
    "----"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-12-11 17:06:01,856 : INFO : collecting all words and their counts\n",
      "2020-12-11 17:06:01,857 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-12-11 17:06:01,889 : INFO : PROGRESS: at sentence #10000, processed 193710 words, keeping 3035 word types\n",
      "2020-12-11 17:06:01,917 : INFO : PROGRESS: at sentence #20000, processed 394373 words, keeping 4980 word types\n",
      "2020-12-11 17:06:01,943 : INFO : PROGRESS: at sentence #30000, processed 577098 words, keeping 6834 word types\n",
      "2020-12-11 17:06:01,968 : INFO : PROGRESS: at sentence #40000, processed 766631 words, keeping 8283 word types\n",
      "2020-12-11 17:06:01,995 : INFO : PROGRESS: at sentence #50000, processed 950406 words, keeping 9560 word types\n",
      "2020-12-11 17:06:02,025 : INFO : PROGRESS: at sentence #60000, processed 1146983 words, keeping 10998 word types\n",
      "2020-12-11 17:06:02,052 : INFO : PROGRESS: at sentence #70000, processed 1338317 words, keeping 11734 word types\n",
      "2020-12-11 17:06:02,072 : INFO : collected 12129 word types from a corpus of 1484518 raw words and 77581 sentences\n",
      "2020-12-11 17:06:02,074 : INFO : Loading a fresh vocabulary\n",
      "2020-12-11 17:06:02,087 : INFO : effective_min_count=3 retains 9461 unique words (78% of original 12129, drops 2668)\n",
      "2020-12-11 17:06:02,088 : INFO : effective_min_count=3 leaves 1480611 word corpus (99% of original 1484518, drops 3907)\n",
      "2020-12-11 17:06:02,112 : INFO : deleting the raw counts dictionary of 12129 items\n",
      "2020-12-11 17:06:02,113 : INFO : sample=0.001 downsamples 71 most-common words\n",
      "2020-12-11 17:06:02,113 : INFO : downsampling leaves estimated 1268096 word corpus (85.6% of prior 1480611)\n",
      "2020-12-11 17:06:02,135 : INFO : estimated required memory for 9461 words and 200 dimensions: 19868100 bytes\n",
      "2020-12-11 17:06:02,136 : INFO : resetting layer weights\n",
      "2020-12-11 17:06:03,682 : INFO : training model with 3 workers on 9461 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-12-11 17:06:04,461 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-11 17:06:04,465 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-11 17:06:04,468 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-11 17:06:04,469 : INFO : EPOCH - 1 : training on 1484518 raw words (1267933 effective words) took 0.8s, 1620644 effective words/s\n",
      "2020-12-11 17:06:05,220 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-11 17:06:05,222 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-11 17:06:05,222 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-11 17:06:05,223 : INFO : EPOCH - 2 : training on 1484518 raw words (1267856 effective words) took 0.7s, 1696374 effective words/s\n",
      "2020-12-11 17:06:05,964 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-11 17:06:05,970 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-11 17:06:05,977 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-11 17:06:05,978 : INFO : EPOCH - 3 : training on 1484518 raw words (1268363 effective words) took 0.7s, 1693091 effective words/s\n",
      "2020-12-11 17:06:06,707 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-11 17:06:06,709 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-11 17:06:06,717 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-11 17:06:06,718 : INFO : EPOCH - 4 : training on 1484518 raw words (1268375 effective words) took 0.7s, 1725238 effective words/s\n",
      "2020-12-11 17:06:07,443 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-11 17:06:07,446 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-11 17:06:07,449 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-11 17:06:07,450 : INFO : EPOCH - 5 : training on 1484518 raw words (1268018 effective words) took 0.7s, 1744032 effective words/s\n",
      "2020-12-11 17:06:07,451 : INFO : training on a 7422590 raw words (6340545 effective words) took 3.8s, 1682549 effective words/s\n",
      "2020-12-11 17:06:07,452 : INFO : saving Word2Vec object under zh_word2vec, separately None\n",
      "2020-12-11 17:06:07,454 : INFO : not storing attribute vectors_norm\n",
      "2020-12-11 17:06:07,455 : INFO : not storing attribute cum_table\n",
      "2020-12-11 17:06:07,575 : INFO : saved zh_word2vec\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(df.CUTTED, min_count = 3, size = 200)\n",
    "model.save('zh_word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'【拓扑适配】【新需求---US20200804307566 OpenORB由于衰退期软件需要切换】【自动发现】导入IP地址后点击保存IP地址，保存后再次打开自动发现，保存的IP只不存在，请定位'"
      ]
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "source": [
    "test_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "New instance is created!\nanimal is running...\n"
     ]
    }
   ],
   "source": [
    "class animal:\n",
    "    count = 0\n",
    "    def run(self):\n",
    "        print('animal is running...')\n",
    "    def __init__(self):\n",
    "        print('New instance is created!')\n",
    "        animal.count += 1\n",
    "class dog(animal):\n",
    "    pass\n",
    "\n",
    "dog1 = dog()\n",
    "dog1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "255e38df16c21428b5ed2c945e084cc2326a94c3e80f49e6b4ed27128f8a2b23"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}